# Technical Design

## Overview

æœ¬è¨­è¨ˆæ›¸ã¯ã€å°èª¬ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ³ã‚¬å½¢å¼ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ˆçµµã‚³ãƒ³ãƒ†ï¼‰ã«è‡ªå‹•å¤‰æ›ã™ã‚‹Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æŠ€è¡“å®Ÿè£…ã«ã¤ã„ã¦å®šç¾©ã—ã¾ã™ã€‚æœ¬ãƒ„ãƒ¼ãƒ«ã¯ç·¨é›†è€…ã‚’è£œä½ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã‚ã‚Šã€ãƒãƒ³ã‚¬ã®çµµãã®ã‚‚ã®ã‚’ç”Ÿæˆã™ã‚‹ã®ã§ã¯ãªãã€ã‚³ãƒå‰²ã‚Šã¨å¹ãå‡ºã—é…ç½®ã®æ§‹æˆæ¡ˆã‚’æä¾›ã—ã¾ã™ã€‚Mastra AIãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€TypeScriptã¨Next.js 14ã‚’ä½¿ç”¨ã—ã¦ã€é•·æ–‡ãƒ†ã‚­ã‚¹ãƒˆã®è§£æã€5è¦ç´ ã®æŠ½å‡ºï¼ˆç™»å ´äººç‰©ãƒ»ã‚·ãƒ¼ãƒ³ãƒ»å¯¾è©±ãƒ»ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ»çŠ¶æ³ï¼‰ã€é€£è¼‰ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ§‹æˆã€ãƒãƒ³ã‚¬ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç”Ÿæˆã‚’å®Ÿç¾ã—ã¾ã™ã€‚

## Requirements Mapping

### Design Component Traceability

å„è¨­è¨ˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒå¯¾å¿œã™ã‚‹è¦ä»¶ï¼š

- **ãƒ†ã‚­ã‚¹ãƒˆè§£æã‚¨ãƒ³ã‚¸ãƒ³** â†’ REQ-1: ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã¨è§£æï¼ˆãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã€ä¼šè©±/åœ°ã®æ–‡è­˜åˆ¥ï¼‰
- **5è¦ç´ æŠ½å‡ºAI** â†’ REQ-1.4: ãƒãƒ£ãƒ³ã‚¯æ¯ã«ä¼šè©±éƒ¨åˆ†ã€åœ°ã®æ–‡ã€ã‚·ãƒ¼ãƒ³è»¢æ›ã®è‡ªå‹•è­˜åˆ¥
- **ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ§‹æˆã‚¨ãƒ³ã‚¸ãƒ³** â†’ REQ-3: é€£è¼‰ãƒãƒ³ã‚¬ã¨ã—ã¦ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ†å‰²
- **ãƒãƒ³ã‚¬ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­è¨ˆã‚¨ãƒ³ã‚¸ãƒ³** â†’ REQ-3: YAMLã§æ¼«ç”»ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’è¨˜è¿°ã™ã‚‹ï¼ˆã‚³ãƒå‰²ã‚Šã¨å¹ãå‡ºã—é…ç½®ï¼‰
- **ãƒãƒ³ã‚¬ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³** â†’ YAMLã‹ã‚‰Canvas APIã§ã€æ ã¨çŠ¶æ³èª¬æ˜ã¨ã‚»ãƒªãƒ•ã«ã‚ˆã‚‹çµµã‚³ãƒ³ãƒ†ã®æç”»ï¼ˆç·¨é›†è€…å‘ã‘ã®æ§‹æˆæ¡ˆã¨ã—ã¦ã€ãƒãƒ³ã‚¬ãã®ã‚‚ã®ã®çµµã¯å«ã¾ãªã„ï¼‰
- **ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚µãƒ¼ãƒ“ã‚¹** â†’ REQ-5: ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã¨å…±æœ‰
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†** â†’ REQ-6: ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¿å­˜

### User Story Coverage

- å°èª¬è‘—è€…ã®ãƒ‹ãƒ¼ã‚º: ãƒ†ã‚­ã‚¹ãƒˆè§£æã‚¨ãƒ³ã‚¸ãƒ³ã¨5è¦ç´ æŠ½å‡ºAIã§è‡ªå‹•ã‚·ãƒ¼ãƒ³è§£æã‚’å®Ÿç¾
- èª­è€…ã®ãƒ‹ãƒ¼ã‚º: Mastraçµ±åˆã«ã‚ˆã‚‹YAMLã§æ§‹é€ åŒ–ã•ã‚ŒãŸãƒãƒ³ã‚¬ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
- ãƒãƒ³ã‚¬åˆ¶ä½œè€…ã®ãƒ‹ãƒ¼ã‚º: æ—¥æœ¬å¼ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã‚‹ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªã‚³ãƒå‰²ã‚Š
- ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãƒ‹ãƒ¼ã‚º: React Server Componentsã«ã‚ˆã‚‹é«˜é€Ÿãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ç·¨é›†
- å…±æœ‰ãƒ‹ãƒ¼ã‚º: Next.js APIãƒ«ãƒ¼ãƒˆã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå‡¦ç†

## Architecture

```mermaid
graph TB
    subgraph "Frontend Layer (Next.js 15.3.3)"
        A[Next.js App Router] --> B[Server Components]
        A --> C[Client Components]
        C --> D[Interactive Editor]
    end

    subgraph "AI Processing Layer (Mastra Agents)"
        E[Mastra Framework] --> F[ChunkAnalyzer Agent]
        E --> G[LayoutGenerator Agent]
        E --> H[NarrativeArcAnalyzer Agent]
        F --> I[5-Element Extractor]
        H --> J[Episode Boundary Detection]
    end

    subgraph "Business Logic Layer"
        K[JobNarrativeProcessor] --> L[DatabaseService]
        M[Panel Layout Engine] --> N[Layout Templates]
        O[Canvas Renderer] --> P[Storyboard Generator]
        Q[Export Service] --> R[Format Converters]
    end

    subgraph "Data Layer"
        S[Cloudflare D1] --> T[Novel/Job/Chunk Tables]
        S --> U[Episode/Layout/Render Tables]
        S --> V[Storage Files Tracking]
        W[Cloudflare R2] --> X[File Storage]
        Y[Local Storage] --> Z[Dev Environment]
    end

    B --> E
    C --> K
    E --> K
    K --> S
    G --> M
    M --> O
    O --> W
    Q --> S
    Q --> W
```

### Technology Stack

èª¿æŸ»çµæœã«åŸºã¥ãæŠ€è¡“é¸å®šï¼š

- **Frontend**: Next.js 15.3.3 (App Router) + TypeScript 5 + Tailwind CSS v4
- **AI Framework**: Mastra (TypeScript agent framework)
- **çµµã‚³ãƒ³ãƒ†ç”Ÿæˆ**: Canvas APIï¼ˆæ ç·šãƒ»ãƒ†ã‚­ã‚¹ãƒˆãƒ»å¹ãå‡ºã—ã®ã¿ã€ã‚¤ãƒ©ã‚¹ãƒˆã¯å«ã¾ãªã„ï¼‰
- **Backend**: Next.js API Routes + Mastra Agents
- **Database**: Cloudflare D1 (SQLite ãƒ™ãƒ¼ã‚¹) / SQLite (é–‹ç™ºç’°å¢ƒ)
- **Cache**: Cloudflare KV (APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥)
- **File Storage**: Cloudflare R2 (ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³) / Local Storage (é–‹ç™º)
- **LLM Providers**: OpenRouter (primary), Gemini, Claude (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³)
- **LLM Factory**: å‹•çš„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½å®Ÿè£…æ¸ˆã¿
- **Configuration**: app.config.ts ã«ã‚ˆã‚‹é›†ä¸­ç®¡ç† + ç’°å¢ƒå¤‰æ•° (ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã®ã¿)
- **Font**: Google Inter (next/font/google)
- **Authentication**: NextAuth.js v5 (æœªå®Ÿè£…)
- **Testing**: Vitest + Playwright + React Testing Library
- **Deployment**: Cloudflare Workers (OpenNext adapter)

### Architecture Decision Rationale

- **Next.js 15.3.3 App Router**: Server Componentsã«ã‚ˆã‚‹é«˜é€Ÿãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã€RSCã«ã‚ˆã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆJSã®å‰Šæ¸›ã€Cloudflare Workerså¯¾å¿œ
- **Mastra Framework**: TypeScriptå®Œå…¨å¯¾å¿œã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€çµ±åˆæ¸ˆã¿ã®LLM/ç”»åƒç”ŸæˆAPIé€£æº
- **Cloudflare D1**: SQLiteãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒƒã‚¸ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€éšå±¤æ§‹é€ ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã€ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¿½è·¡
- **Cloudflare R2**: S3äº’æ›APIã€ã‚¨ãƒƒã‚¸é…ä¿¡ã€ã‚³ã‚¹ãƒˆåŠ¹ç‡
- **Cloudflare Workers**: ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¨ãƒƒã‚¸é…ä¿¡ã€ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã€è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€KVã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±åˆ
- **è¨­å®šç®¡ç†**: app.config.ts ã«ã‚ˆã‚‹ä¸€å…ƒç®¡ç†ã€ç’°å¢ƒå¤‰æ•°ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã‚³ãƒ¡ãƒ³ãƒˆä»˜ã
- **LLMãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³**: openrouter â†’ gemini â†’ claude ã®è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€å¯ç”¨æ€§å‘ä¸Š
- **StorageFactory Pattern**: ç’°å¢ƒåˆ¥ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æŠ½è±¡åŒ–ã€é–‹ç™ºãƒ»æœ¬ç•ªç’°å¢ƒã®è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ

## Data Flow

### Primary User Flow: ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒãƒ³ã‚¬ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç”Ÿæˆ

```mermaid
sequenceDiagram
    participant User
    participant RSC as Server Component
    participant Mastra as Mastra Agent
    participant AI as AI Services
    participant DB as Database
    participant Storage as R2 Storage
    participant Canvas as Canvas API

    User->>RSC: å°èª¬ãƒ†ã‚­ã‚¹ãƒˆæŠ•ç¨¿
    RSC->>Mastra: ãƒ†ã‚­ã‚¹ãƒˆè§£æãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    Mastra->>AI: ãƒãƒ£ãƒ³ã‚¯æ¯ã®5è¦ç´ æŠ½å‡º
    AI-->>Mastra: è¦ç´ ãƒ‡ãƒ¼ã‚¿ï¼ˆç™»å ´äººç‰©ã€ã‚·ãƒ¼ãƒ³ã€å¯¾è©±ã€ãƒã‚¤ãƒ©ã‚¤ãƒˆã€çŠ¶æ³ï¼‰
    Mastra->>Mastra: å…¨ãƒãƒ£ãƒ³ã‚¯ã®çµ±åˆåˆ†æ
    Mastra->>AI: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ§‹æˆåˆ†æ
    AI-->>Mastra: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ†å‰²æ¡ˆ
    Mastra->>AI: ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆYAMLç”Ÿæˆ
    AI-->>Mastra: ã‚³ãƒå‰²ã‚Šãƒ»å¹ãå‡ºã—é…ç½®YAML
    Mastra->>Canvas: ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæç”»ï¼ˆæ ç·šãƒ»ãƒ†ã‚­ã‚¹ãƒˆãƒ»å¹ãå‡ºã—ã®ã¿ï¼‰
    Canvas-->>Storage: çµµã‚³ãƒ³ãƒ†ç”»åƒä¿å­˜
    Mastra->>DB: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¿å­˜
    Mastra-->>RSC: ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆçµæœ
    RSC-->>User: çµµã‚³ãƒ³ãƒ†ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
```

### ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ§‹æˆã¨ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç”Ÿæˆãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant Chunks as Chunk Analyses
    participant Integration as Integration Service
    participant Episode as Episode Composer
    participant Layout as Layout Engine
    participant Canvas as Canvas Renderer
    participant Output as Output Files

    Chunks->>Integration: ãƒãƒ£ãƒ³ã‚¯æ¯ã®5è¦ç´ ãƒ‡ãƒ¼ã‚¿
    Integration->>Integration: é‡è¤‡æ’é™¤ãƒ»çµ±åˆ
    Integration->>Episode: çµ±åˆæ¸ˆã¿è§£æãƒ‡ãƒ¼ã‚¿
    Episode->>Episode: ãƒãƒ£ãƒ—ã‚¿ãƒ¼åˆ†å‰²
    Episode->>Episode: ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹æ¤œå‡º
    Episode->>Layout: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ§‹æˆ
    Layout->>Layout: ã‚³ãƒå‰²ã‚Šè¨ˆç®—ï¼ˆé‡è¦åº¦ãƒ™ãƒ¼ã‚¹ï¼‰
    Layout->>Layout: å¹ãå‡ºã—é…ç½®ï¼ˆèª­ã¿é †è€ƒæ…®ï¼‰
    Layout->>Canvas: ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆYAML
    Canvas->>Canvas: æ ç·šæç”»
    Canvas->>Canvas: çŠ¶æ³èª¬æ˜ãƒ†ã‚­ã‚¹ãƒˆé…ç½®
    Canvas->>Canvas: ã‚»ãƒªãƒ•å¹ãå‡ºã—æç”»
    Canvas-->>Output: çµµã‚³ãƒ³ãƒ†ç”»åƒï¼ˆPNGï¼‰
```

## Components and Interfaces

### Backend Services & Method Signatures

```typescript
// Mastra Agentå®šç¾©ï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰
// ChunkAnalyzerAgent - ãƒãƒ£ãƒ³ã‚¯åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
const chunkAnalyzerAgent = new Agent({
  name: 'chunk-analyzer',
  description: 'å°èª¬ã®ãƒãƒ£ãƒ³ã‚¯ã‚’åˆ†æã—ã¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€å ´é¢ã€å¯¾è©±ã€ãƒã‚¤ãƒ©ã‚¤ãƒˆã€çŠ¶æ³ã‚’æŠ½å‡ºã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ',
  instructions: () => getTextAnalysisConfig().systemPrompt,
  model: async () => {
    const llm = await getTextAnalysisLLM()
    return llm.provider(llm.model)
  }
})

// NarrativeArcAnalyzerAgent - ç‰©èªæ§‹é€ åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
const narrativeArcAnalyzerAgent = new Agent({
  name: 'narrative-arc-analyzer',
  description: 'å°èª¬å…¨ä½“ã®ç‰©èªæ§‹é€ ã‚’åˆ†æã—ã¦ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å¢ƒç•Œã‚’æ¤œå‡ºã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ',
  instructions: () => getNarrativeAnalysisConfig().systemPrompt,
  model: async () => {
    const llm = await getNarrativeAnalysisLLM()
    return llm.provider(llm.model)
  }
})

// LayoutGeneratorAgent - ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
const layoutGeneratorAgent = new Agent({
  name: 'layout-generator',
  description: 'ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ†æçµæœã‹ã‚‰ãƒãƒ³ã‚¬ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆYAMLã‚’ç”Ÿæˆã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ',
  instructions: () => getLayoutGenerationConfig().systemPrompt,
  model: async () => {
    const llm = await getLayoutGenerationLLM()
    return llm.provider(llm.model)
  }
})

// LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š
interface LLMProviderConfig {
  provider: 'openai' | 'gemini' | 'groq' | 'local' | 'openrouter' | 'claude';
  apiKey?: string;
  model: string;
  temperature?: number;
  maxTokens?: number;
  timeout?: number;
}

// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³æ©Ÿèƒ½ï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰
// LLM Factoryé–¢æ•°ç¾¤
export async function getTextAnalysisLLM() {
  const config = getTextAnalysisConfig()
  const preferredProvider = config.provider === 'default' ? appConfig.llm.defaultProvider : config.provider
  const llmInstance = await getProviderWithFallback(preferredProvider)
  return llmInstance
}

export async function getNarrativeAnalysisLLM() {
  const config = getNarrativeAnalysisConfig()
  const preferredProvider = config.provider === 'default' ? appConfig.llm.defaultProvider : config.provider
  return await getProviderWithFallback(preferredProvider)
}

export async function getProviderWithFallback(preferredProvider?: string) {
  // appConfig.llmFallbackChainã«åŸºã¥ããƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å®Ÿè£…
  // openrouter â†’ gemini â†’ claude ã®é †ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
}

// ã‚¸ãƒ§ãƒ–ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰
export class JobNarrativeProcessor {
  constructor(config: NarrativeProcessorConfig) {
    this.config = config
    this.dbService = new DatabaseService()
  }

  async processJob(
    jobId: string,
    onProgress?: (progress: JobProgress) => void
  ): Promise<JobProgress> {
    // åˆ†å‰²â†’åˆ†æâ†’ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ†æã®å®Œå…¨ãƒ•ãƒ­ãƒ¼å®Ÿè£…æ¸ˆã¿
  }

  async canResumeJob(jobId: string): Promise<boolean> {
    // ã‚¸ãƒ§ãƒ–å†é–‹å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯å®Ÿè£…æ¸ˆã¿
  }
}

// ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰
// src/services/database.ts ã§å®Œå…¨å®Ÿè£…æ¸ˆã¿
/*
export class DatabaseService {
  private db = getDatabase()

  // Novelç®¡ç† - å®Ÿè£…æ¸ˆã¿
  async createNovel(novel: Omit<Novel, 'id' | 'createdAt'>): Promise<string>
  async getNovel(id: string): Promise<Novel | null>
  async getAllNovels(): Promise<Novel[]>
  async ensureNovel(novel: Omit<Novel, 'id' | 'createdAt'>): Promise<string>

  // Jobç®¡ç† - å®Ÿè£…æ¸ˆã¿
  async createJob(job: Omit<Job, 'id' | 'createdAt'>): Promise<string>
  async getJob(id: string): Promise<Job | null>
  async getJobWithProgress(id: string): Promise<JobWithProgress | null>
  async updateJobStatus(id: string, status: JobStatus, error?: string): Promise<void>
  async updateJobProgress(id: string, progress: Partial<JobProgress>): Promise<void>
  async updateJobStep(id: string, step: JobStep, metadata?: any): Promise<void>
  async updateJobError(id: string, error: string, step: string): Promise<void>
  async markJobStepCompleted(id: string, step: JobStep): Promise<void>
  async getJobsByNovelId(novelId: string): Promise<Job[]>

  // Chunkç®¡ç† - å®Ÿè£…æ¸ˆã¿
  async createChunk(chunk: Omit<Chunk, 'id' | 'createdAt'>): Promise<string>
  async getChunksByJobId(jobId: string): Promise<Chunk[]>

  // Episodeç®¡ç† - å®Ÿè£…æ¸ˆã¿
  async createEpisode(episode: Omit<Episode, 'id' | 'createdAt'>): Promise<string>
  async createEpisodes(episodes: Episode[]): Promise<void>
  async getEpisodesByJobId(jobId: string): Promise<Episode[]>

  // ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°çŠ¶æ…‹ç®¡ç† - å®Ÿè£…æ¸ˆã¿
  async updateRenderStatus(status: RenderStatusUpdate): Promise<void>
}
*/
```

### Frontend Components

| Component Name | Responsibility | Props/State Summary | Status |
|----------------|----------------|---------------------|--------|
| HomeClient | ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå¢ƒç•Œã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | sampleText, processing states | Implemented |
| TextInputArea | ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›UI | text, onChange, maxLength, characterCount | Implemented |
| ProcessingProgress | å‡¦ç†é€²æ—è¡¨ç¤º | currentStep, progress, message | Implemented |
| ResultsDisplay | çµæœè¡¨ç¤ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | episodes, layouts, renders | Implemented |
| Logger | ãƒ­ã‚°è¡¨ç¤ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | logs, maxLogs | Implemented |
| NovelUploader | å°èª¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰UI | onUpload, accepted formats | Partially |
| MangaPreview | ãƒãƒ³ã‚¬ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º | layout, panels, editable | Not Implemented |
| PanelEditor | ã‚³ãƒç·¨é›†ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ | panel, onResize, onMove | Not Implemented |
| SpeechBubbleEditor | å¹ãå‡ºã—ç·¨é›† | bubble, text, style, onEdit | Not Implemented |
| ExportDialog | ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆè¨­å®š | formats, onExport | Not Implemented |
| ProjectManager | ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†UI | projects, onSave, onLoad | Not Implemented |

### API Endpoints

| Method | Route | Purpose | Auth | Status Codes |
|--------|-------|---------|------|--------------|
| POST | /api/novel | å°èª¬ç™»éŒ²ï¼ˆãƒ†ã‚­ã‚¹ãƒˆ + ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰ | Implemented | 200, 400, 413, 500 |
| GET | /api/novel/storage/:id | å°èª¬ãƒ†ã‚­ã‚¹ãƒˆå–å¾— | Implemented | 200, 404, 500 |
| POST | /api/novel/db | å°èª¬ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿DBä¿å­˜ | Implemented | 200, 400, 500 |
| GET | /api/novel/[uuid]/chunks | ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ãƒ»å–å¾— | Implemented | 200, 404, 500 |
| POST | /api/analyze | çµ±åˆåˆ†æï¼ˆãƒãƒ£ãƒ³ã‚¯åˆ†å‰²â†’åˆ†æâ†’ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ†æï¼‰ | Implemented | 200, 400, 500 |
| POST | /api/analyze/chunk | ãƒãƒ£ãƒ³ã‚¯å˜ä½ã®5è¦ç´ åˆ†æ | Implemented | 200, 400, 500 |
| POST | /api/analyze/episode | ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å¢ƒç•Œåˆ†æ | Implemented | 200, 400, 500 |
| POST | /api/analyze/narrative-arc/full | å…¨ä½“ç‰©èªæ§‹é€ åˆ†æ | Implemented | 200, 400, 500 |
| GET | /api/job/[id] | ã‚¸ãƒ§ãƒ–æƒ…å ±å–å¾— | Implemented | 200, 404, 500 |
| GET | /api/jobs/[jobId]/status | ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾— | Implemented | 200, 404, 500 |
| GET | /api/jobs/[jobId]/episodes | ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¸€è¦§å–å¾— | Implemented | 200, 404, 500 |
| POST | /api/jobs/[jobId]/resume | ã‚¸ãƒ§ãƒ–å†é–‹ | Implemented | 200, 400, 404, 500 |
| POST | /api/layout/generate | ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆYAMLç”Ÿæˆ | Implemented | 200, 400, 500 |
| POST | /api/render | Canvasãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° | Implemented | 201, 400, 500 |
| POST | /api/render/batch | ãƒãƒƒãƒãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° | Implemented | 201, 400, 500 |
| GET | /api/render/status/[jobId] | ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°çŠ¶æ³ç¢ºèª | Implemented | 200, 400, 500 |
| POST | /api/export | ãƒãƒ³ã‚¬ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆPDFãƒ»ZIPï¼‰ | Partially Implemented | 201, 400, 500 |
| POST | /api/share | å…±æœ‰ãƒªãƒ³ã‚¯ç”Ÿæˆ | Partially Implemented | 201, 401, 500 |

## Data Models

### Domain Entities (æ–°ã‚¹ã‚­ãƒ¼ãƒå¯¾å¿œ)

1. **Novel**: å°èª¬ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆæœ€ä¸Šä½ï¼‰
2. **Job**: å¤‰æ›ã‚¸ãƒ§ãƒ–ï¼ˆNovelã«å¯¾ã™ã‚‹å‡¦ç†å˜ä½ï¼‰
3. **JobStepHistory**: å„å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã®å±¥æ­´
4. **Chunk**: åˆ†å‰²ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯
5. **ChunkAnalysisStatus**: ãƒãƒ£ãƒ³ã‚¯åˆ†æçŠ¶æ…‹
6. **Episode**: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å¢ƒç•Œæƒ…å ±
7. **LayoutStatus**: ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç”ŸæˆçŠ¶æ…‹
8. **RenderStatus**: æç”»çŠ¶æ…‹
9. **Output**: æœ€çµ‚æˆæœç‰©
10. **StorageFiles**: ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†

### Entity Relationships

```mermaid
erDiagram
    NOVEL ||--|{ JOB : "has multiple"
    JOB ||--|{ CHUNK : "divided into"
    JOB ||--|{ JOB_STEP_HISTORY : "has history"
    JOB ||--|{ CHUNK_ANALYSIS_STATUS : "tracks analysis"
    JOB ||--|{ EPISODE : "generates"
    JOB ||--|{ LAYOUT_STATUS : "tracks layout"
    JOB ||--|{ RENDER_STATUS : "tracks render"
    JOB ||--|{ OUTPUT : "produces"
    NOVEL ||--|{ STORAGE_FILES : "has files"

    NOVEL {
        string id PK
        string title
        string author
        string original_text_path
        number text_length
        string language
        string metadata_path
        datetime created_at
        datetime updated_at
    }

    JOB {
        string id PK
        string novel_id FK
        string job_name
        string status
        string current_step
        boolean split_completed
        boolean analyze_completed
        boolean episode_completed
        boolean layout_completed
        boolean render_completed
        string chunks_dir_path
        string analyses_dir_path
        string episodes_data_path
        string layouts_dir_path
        string renders_dir_path
        number total_chunks
        number processed_chunks
        number total_episodes
        number processed_episodes
        number total_pages
        number rendered_pages
        string last_error
        string last_error_step
        number retry_count
        string resume_data_path
        datetime created_at
        datetime updated_at
        datetime started_at
        datetime completed_at
    }

    CHUNK {
        string id PK
        string novel_id FK
        string job_id FK
        number chunk_index
        string content_path
        number start_position
        number end_position
        number word_count
        datetime created_at
    }
```

### Data Model Definitions

```typescript
// TypeScript å‹å®šç¾©ï¼ˆDrizzle ORM + Zodã‚¹ã‚­ãƒ¼ãƒçµ±åˆï¼‰

// Core Models - Drizzleè‡ªå‹•ç”Ÿæˆå‹ã¨Zodã‚¹ã‚­ãƒ¼ãƒã®ä½µç”¨
export type Novel = typeof novels.$inferSelect    // Drizzleè‡ªå‹•ç”Ÿæˆ
export type NewNovel = typeof novels.$inferInsert // Insertç”¨
export type Job = typeof jobs.$inferSelect        // Drizzleè‡ªå‹•ç”Ÿæˆ
export type NewJob = typeof jobs.$inferInsert     // Insertç”¨
export type Chunk = typeof chunks.$inferSelect
export type NewChunk = typeof chunks.$inferInsert
export type Episode = typeof episodes.$inferSelect
export type NewEpisode = typeof episodes.$inferInsert
export type StorageFile = typeof storageFiles.$inferSelect
export type NewStorageFile = typeof storageFiles.$inferInsert

// Zodã‚¹ã‚­ãƒ¼ãƒãƒ™ãƒ¼ã‚¹å‹ï¼ˆãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãï¼‰
export type NovelZod = z.infer<typeof NovelSchema>
export type JobZod = z.infer<typeof JobSchema>
export type TextAnalysis = z.infer<typeof TextAnalysisSchema>

// åˆ†æçµæœå‹ï¼ˆçµ±åˆå®šç¾©ï¼‰
export interface ChunkAnalysisResult {
  chunkIndex: number
  characters: Array<{
    name: string
    role: 'protagonist' | 'antagonist' | 'supporting' | 'minor'
    description?: string
  }>
  scenes: Array<{
    location: string
    timeOfDay?: string
    atmosphere?: string
    description?: string
  }>
  dialogues: Array<{
    speaker: string
    content: string
    emotion?: string
    importance: 'high' | 'medium' | 'low'
  }>
  highlights: Array<{
    type: 'action' | 'emotion' | 'plot' | 'description'
    content: string
    importance: number
    intensity: number
    relevance: number
    startIndex: number
    endIndex: number
  }>
  situations: Array<{
    type: 'conflict' | 'resolution' | 'transition' | 'development'
    description: string
    significance: number
  }>
  narrativeElements: {
    tension: number
    pacing: 'slow' | 'medium' | 'fast'
    emotionalTone: string
    plotRelevance: number
  }
}

// ãƒãƒ³ã‚¬ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå‹
export interface MangaLayout {
  title: string
  author?: string
  created_at: string
  episodeNumber: number
  episodeTitle?: string
  pages: Page[]
}

export interface Page {
  pageNumber: number
  panels: Panel[]
  dimensions: {
    width: number
    height: number
  }
}

export interface Panel {
  id: string
  position: {
    x: number
    y: number
    width: number
    height: number
  }
  content: {
    type: 'dialogue' | 'narration' | 'action' | 'transition'
    text?: string
    speaker?: string
    emotion?: string
  }
  speechBubbles?: SpeechBubble[]
}

export interface SpeechBubble {
  id: string
  position: {
    x: number
    y: number
    width: number
    height: number
  }
  style: 'speech' | 'thought' | 'narration' | 'effect'
  text: string
  speaker?: string
  tailPosition?: {
    x: number
    y: number
  }
}

// çµ±åˆåˆ†æå‹ï¼ˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ†æçµæœï¼‰
export interface NarrativeArcAnalysis {
  episodes: Array<{
    episodeNumber: number
    title?: string
    summary?: string
    startChunk: number
    startCharIndex: number
    endChunk: number
    endCharIndex: number
    estimatedPages: number
    confidence: number
    keyEvents: string[]
    emotionalArc: string[]
  }>
  overallStructure: {
    totalEpisodes: number
    averageEpisodeLength: number
    genreClassification: string[]
    mainThemes: string[]
  }
  metadata: {
    analysisTimestamp: string
    processingTimeMs: number
    modelUsed: string
  }
}

// Zodã‚¹ã‚­ãƒ¼ãƒä¾‹ï¼ˆå‚è€ƒï¼‰
/*
const NovelSchema = z.object({
  id: z.string(),
  title: z.string().optional(),
  author: z.string().optional(),
  originalTextPath: z.string(),
  textLength: z.number(),
  language: z.string(),
  metadataPath: z.string().optional(),
  createdAt: z.date(),
  updatedAt: z.date(),
})

const TextAnalysisSchema = z.object({
  id: z.string(),
  chunkId: z.string().optional(),
  characters: z.array(CharacterSchema),
  scenes: z.array(SceneSchema),
  dialogues: z.array(DialogueSchema),
  highlights: z.array(HighlightSchema),
  situations: z.array(SituationSchema),
  createdAt: z.date(),
  updatedAt: z.date(),
})
*/
```

### Database Schema (Drizzle ORM)

ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã¯Drizzle ORMã‚’ä½¿ç”¨ã—ã¦å®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚

```typescript
// src/db/schema.ts - Drizzle Schema Definition

// å°èª¬ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæœ€ä¸Šä½ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼‰
export const novels = sqliteTable(
  'novels',
  {
    id: text('id').primaryKey(),
    title: text('title'),
    author: text('author'),
    originalTextPath: text('original_text_path').notNull(), // ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä¸Šã®å°èª¬ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    textLength: integer('text_length').notNull(),
    language: text('language').default('ja'),
    metadataPath: text('metadata_path'), // ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä¸Šã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    createdAt: text('created_at').default(sql`CURRENT_TIMESTAMP`),
    updatedAt: text('updated_at').default(sql`CURRENT_TIMESTAMP`),
  },
  (table) => ({
    createdAtIdx: index('idx_novels_created_at').on(table.createdAt),
  }),
)

// å¤‰æ›ã‚¸ãƒ§ãƒ–ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå°èª¬ã«å¯¾ã™ã‚‹å¤‰æ›å‡¦ç†ï¼‰
export const jobs = sqliteTable(
  'jobs',
  {
    id: text('id').primaryKey(),
    novelId: text('novel_id')
      .notNull()
      .references(() => novels.id, { onDelete: 'cascade' }),
    jobName: text('job_name'),

    // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç®¡ç†
    status: text('status').notNull().default('pending'), // pending/processing/completed/failed/paused
    currentStep: text('current_step').notNull().default('initialized'), // initialized/split/analyze/episode/layout/render/complete

    // å„ã‚¹ãƒ†ãƒƒãƒ—ã®å®Œäº†çŠ¶æ…‹
    splitCompleted: integer('split_completed', { mode: 'boolean' }).default(false),
    analyzeCompleted: integer('analyze_completed', { mode: 'boolean' }).default(false),
    episodeCompleted: integer('episode_completed', { mode: 'boolean' }).default(false),
    layoutCompleted: integer('layout_completed', { mode: 'boolean' }).default(false),
    renderCompleted: integer('render_completed', { mode: 'boolean' }).default(false),

    // å„ã‚¹ãƒ†ãƒƒãƒ—ã®æˆæœç‰©ãƒ‘ã‚¹ï¼ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰
    chunksDirPath: text('chunks_dir_path'),
    analysesDirPath: text('analyses_dir_path'),
    episodesDataPath: text('episodes_data_path'),
    layoutsDirPath: text('layouts_dir_path'),
    rendersDirPath: text('renders_dir_path'),

    // é€²æ—è©³ç´°
    totalChunks: integer('total_chunks').default(0),
    processedChunks: integer('processed_chunks').default(0),
    totalEpisodes: integer('total_episodes').default(0),
    processedEpisodes: integer('processed_episodes').default(0),
    totalPages: integer('total_pages').default(0),
    renderedPages: integer('rendered_pages').default(0),

    // ã‚¨ãƒ©ãƒ¼ç®¡ç†
    lastError: text('last_error'),
    lastErrorStep: text('last_error_step'),
    retryCount: integer('retry_count').default(0),

    // å†é–‹ç”¨ã®çŠ¶æ…‹ä¿å­˜
    resumeDataPath: text('resume_data_path'),

    // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    createdAt: text('created_at').default(sql`CURRENT_TIMESTAMP`),
    updatedAt: text('updated_at').default(sql`CURRENT_TIMESTAMP`),
    startedAt: text('started_at'),
    completedAt: text('completed_at'),
  },
  (table) => ({
    novelIdIdx: index('idx_jobs_novel_id').on(table.novelId),
    statusIdx: index('idx_jobs_status').on(table.status),
    novelIdStatusIdx: index('idx_jobs_novel_id_status').on(table.novelId, table.status),
    currentStepIdx: index('idx_jobs_current_step').on(table.currentStep),
  }),
)

// ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒƒãƒ—å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå„ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè¡Œè¨˜éŒ²ï¼‰
export const jobStepHistory = sqliteTable(
  'job_step_history',
  {
    id: text('id').primaryKey(),
    jobId: text('job_id')
      .notNull()
      .references(() => jobs.id, { onDelete: 'cascade' }),
    stepName: text('step_name').notNull(), // split/analyze/episode/layout/render
    status: text('status').notNull(), // started/completed/failed/skipped
    startedAt: text('started_at').notNull(),
    completedAt: text('completed_at'),
    durationSeconds: integer('duration_seconds'),
    inputPath: text('input_path'),
    outputPath: text('output_path'),
    errorMessage: text('error_message'),
    metadata: text('metadata'), // JSONå½¢å¼ã®è¿½åŠ æƒ…å ±
    createdAt: text('created_at').default(sql`CURRENT_TIMESTAMP`),
  },
  (table) => ({
    jobIdIdx: index('idx_job_step_history_job_id').on(table.jobId),
  }),
)

// ãƒãƒ£ãƒ³ã‚¯ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆåˆ†å‰²ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆï¼‰
export const chunks = sqliteTable(
  'chunks',
  {
    id: text('id').primaryKey(),
    novelId: text('novel_id')
      .notNull()
      .references(() => novels.id, { onDelete: 'cascade' }),
    jobId: text('job_id')
      .notNull()
      .references(() => jobs.id, { onDelete: 'cascade' }),
    chunkIndex: integer('chunk_index').notNull(),
    contentPath: text('content_path').notNull(),
    startPosition: integer('start_position').notNull(),
    endPosition: integer('end_position').notNull(),
    wordCount: integer('word_count'),
    createdAt: text('created_at').default(sql`CURRENT_TIMESTAMP`),
  },
  (table) => ({
    novelIdIdx: index('idx_chunks_novel_id').on(table.novelId),
    jobIdIdx: index('idx_chunks_job_id').on(table.jobId),
    uniqueJobChunk: index('unique_job_chunk').on(table.jobId, table.chunkIndex),
  }),
)

// ãƒãƒ£ãƒ³ã‚¯åˆ†æçŠ¶æ…‹ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå„ãƒãƒ£ãƒ³ã‚¯ã®åˆ†æå®Œäº†çŠ¶æ…‹ï¼‰
export const chunkAnalysisStatus = sqliteTable(
  'chunk_analysis_status',
  {
    id: text('id').primaryKey(),
    jobId: text('job_id')
      .notNull()
      .references(() => jobs.id, { onDelete: 'cascade' }),
    chunkIndex: integer('chunk_index').notNull(),
    isAnalyzed: integer('is_analyzed', { mode: 'boolean' }).default(false),
    analysisPath: text('analysis_path'),
    analyzedAt: text('analyzed_at'),
    retryCount: integer('retry_count').default(0),
    lastError: text('last_error'),
    createdAt: text('created_at').default(sql`CURRENT_TIMESTAMP`),
  },
  (table) => ({
    jobIdIdx: index('idx_chunk_analysis_status_job_id').on(table.jobId),
    uniqueJobChunk: index('unique_job_chunk_analysis').on(table.jobId, table.chunkIndex),
  }),
)

// ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ†ãƒ¼ãƒ–ãƒ«
export const episodes = sqliteTable(
  'episodes',
  {
    id: text('id').primaryKey(),
    novelId: text('novel_id')
      .notNull()
      .references(() => novels.id, { onDelete: 'cascade' }),
    jobId: text('job_id')
      .notNull()
      .references(() => jobs.id, { onDelete: 'cascade' }),
    episodeNumber: integer('episode_number').notNull(),
    title: text('title'),
    summary: text('summary'),
    startChunk: integer('start_chunk').notNull(),
    startCharIndex: integer('start_char_index').notNull(),
    endChunk: integer('end_chunk').notNull(),
    endCharIndex: integer('end_char_index').notNull(),
    estimatedPages: integer('estimated_pages').notNull(),
    confidence: real('confidence').notNull(),
    createdAt: text('created_at').default(sql`CURRENT_TIMESTAMP`),
  },
  (table) => ({
    novelIdIdx: index('idx_episodes_novel_id').on(table.novelId),
    jobIdIdx: index('idx_episodes_job_id').on(table.jobId),
    uniqueJobEpisode: index('unique_job_episode').on(table.jobId, table.episodeNumber),
  }),
)

// ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆçŠ¶æ…‹ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç”ŸæˆçŠ¶æ…‹ï¼‰
export const layoutStatus = sqliteTable(
  'layout_status',
  {
    id: text('id').primaryKey(),
    jobId: text('job_id')
      .notNull()
      .references(() => jobs.id, { onDelete: 'cascade' }),
    episodeNumber: integer('episode_number').notNull(),
    isGenerated: integer('is_generated', { mode: 'boolean' }).default(false),
    layoutPath: text('layout_path'),
    totalPages: integer('total_pages'),
    totalPanels: integer('total_panels'),
    generatedAt: text('generated_at'),
    retryCount: integer('retry_count').default(0),
    lastError: text('last_error'),
    createdAt: text('created_at').default(sql`CURRENT_TIMESTAMP`),
  },
  (table) => ({
    jobIdIdx: index('idx_layout_status_job_id').on(table.jobId),
    uniqueJobEpisode: index('unique_job_episode_layout').on(table.jobId, table.episodeNumber),
  }),
)

// æç”»çŠ¶æ…‹ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå„ãƒšãƒ¼ã‚¸ã®æç”»çŠ¶æ…‹ï¼‰
export const renderStatus = sqliteTable(
  'render_status',
  {
    id: text('id').primaryKey(),
    jobId: text('job_id')
      .notNull()
      .references(() => jobs.id, { onDelete: 'cascade' }),
    episodeNumber: integer('episode_number').notNull(),
    pageNumber: integer('page_number').notNull(),
    isRendered: integer('is_rendered', { mode: 'boolean' }).default(false),
    imagePath: text('image_path'),
    thumbnailPath: text('thumbnail_path'),
    width: integer('width'),
    height: integer('height'),
    fileSize: integer('file_size'),
    renderedAt: text('rendered_at'),
    retryCount: integer('retry_count').default(0),
    lastError: text('last_error'),
    createdAt: text('created_at').default(sql`CURRENT_TIMESTAMP`),
  },
  (table) => ({
    jobIdIdx: index('idx_render_status_job_id').on(table.jobId),
    uniqueJobEpisodePage: index('unique_job_episode_page').on(
      table.jobId,
      table.episodeNumber,
      table.pageNumber,
    ),
  }),
)

// æœ€çµ‚æˆæœç‰©ãƒ†ãƒ¼ãƒ–ãƒ«
export const outputs = sqliteTable(
  'outputs',
  {
    id: text('id').primaryKey(),
    novelId: text('novel_id')
      .notNull()
      .references(() => novels.id, { onDelete: 'cascade' }),
    jobId: text('job_id')
      .notNull()
      .references(() => jobs.id, { onDelete: 'cascade' }),
    outputType: text('output_type').notNull(), // pdf/images_zip
    outputPath: text('output_path').notNull(),
    fileSize: integer('file_size'),
    pageCount: integer('page_count'),
    metadataPath: text('metadata_path'),
    createdAt: text('created_at').default(sql`CURRENT_TIMESTAMP`),
  },
  (table) => ({
    novelIdIdx: index('idx_outputs_novel_id').on(table.novelId),
    jobIdIdx: index('idx_outputs_job_id').on(table.jobId),
  }),
)

// ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å‚ç…§ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®è¿½è·¡ï¼‰
export const storageFiles = sqliteTable(
  'storage_files',
  {
    id: text('id').primaryKey(),
    novelId: text('novel_id')
      .notNull()
      .references(() => novels.id, { onDelete: 'cascade' }),
    jobId: text('job_id').references(() => jobs.id, { onDelete: 'cascade' }),
    filePath: text('file_path').notNull().unique(),
    fileCategory: text('file_category').notNull(), // original/chunk/analysis/episode/layout/render/output/metadata
    fileType: text('file_type').notNull(), // txt/json/yaml/png/jpg/pdf/zip
    mimeType: text('mime_type'), // è¿½åŠ : å®Ÿéš›ã®MIMEã‚¿ã‚¤ãƒ— (ä¾‹: 'image/png')
    fileSize: integer('file_size'),
    createdAt: text('created_at').default(sql`CURRENT_TIMESTAMP`),
  },
  (table) => ({
    novelIdIdx: index('idx_storage_files_novel_id').on(table.novelId),
  }),
)

// ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯Drizzleãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©å†…ã§ç®¡ç†ï¼š
// - novels: createdAtIdx
// - jobs: novelIdIdx, statusIdx, novelIdStatusIdx, currentStepIdx
// - jobStepHistory: jobIdIdx
// - chunks: novelIdIdx, jobIdIdx, uniqueJobChunk
// - chunkAnalysisStatus: jobIdIdx, uniqueJobChunkAnalysis
// - episodes: novelIdIdx, jobIdIdx, uniqueJobEpisode
// - layoutStatus: jobIdIdx, uniqueJobEpisode
// - renderStatus: jobIdIdx, uniqueJobEpisodePage
// - outputs: novelIdIdx, jobIdIdx
// - storageFiles: novelIdIdx

// å‹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆDrizzleè‡ªå‹•ç”Ÿæˆï¼‰
export type Novel = typeof novels.$inferSelect
export type NewNovel = typeof novels.$inferInsert
export type Job = typeof jobs.$inferSelect
export type NewJob = typeof jobs.$inferInsert
export type Episode = typeof episodes.$inferSelect
export type NewEpisode = typeof episodes.$inferInsert
// ãã®ä»–ã™ã¹ã¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«å‹ã‚‚åŒæ§˜ã«è‡ªå‹•ç”Ÿæˆ

// ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ“ãƒ¥ãƒ¼ã¯Drizzleã§ã¯ç›´æ¥ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãŸã‚ã€
// å¿…è¦ã«å¿œã˜ã¦ã‚¯ã‚¨ãƒªãƒ“ãƒ«ãƒ€ãƒ¼ã§è¤‡é›‘ãªé›†è¨ˆã‚’å®Ÿè£…

// å°èª¬ã®å¤‰æ›çŠ¶æ³å–å¾—ä¾‹ï¼š
/*
const novelStatusQuery = db
  .select({
    id: novels.id,
    title: novels.title,
    author: novels.author,
    totalJobs: count(jobs.id),
    completedJobs: count(case(when(eq(jobs.status, 'completed'), jobs.id), else(null))),
    activeJobs: count(case(when(eq(jobs.status, 'processing'), jobs.id), else(null))),
    totalOutputs: count(outputs.id),
    createdAt: novels.createdAt,
    lastJobCreatedAt: max(jobs.createdAt),
  })
  .from(novels)
  .leftJoin(jobs, eq(novels.id, jobs.novelId))
  .leftJoin(outputs, eq(novels.id, outputs.novelId))
  .groupBy(novels.id);
*/
```

### R2 Storage Structure

ç¾åœ¨å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹çµ±åˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ§‹é€ ï¼š

```
novels/
â””â”€â”€ {novelId}/
    â”œâ”€â”€ original/
    â”‚   â”œâ”€â”€ text.txt                    # å…ƒã®å°èª¬ãƒ†ã‚­ã‚¹ãƒˆ
    â”‚   â””â”€â”€ metadata.json              # å°èª¬ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    â”‚
    â””â”€â”€ jobs/
        â””â”€â”€ {jobId}/
            â”œâ”€â”€ chunks/
            â”‚   â”œâ”€â”€ chunk_001.txt       # ãƒãƒ£ãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆ
            â”‚   â”œâ”€â”€ chunk_002.txt
            â”‚   â””â”€â”€ ...
            â”‚
            â”œâ”€â”€ analyses/
            â”‚   â”œâ”€â”€ chunk_001.json      # ãƒãƒ£ãƒ³ã‚¯åˆ†æçµæœ
            â”‚   â”œâ”€â”€ chunk_002.json
            â”‚   â””â”€â”€ ...
            â”‚
            â”œâ”€â”€ episodes/
            â”‚   â”œâ”€â”€ episodes.json       # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¸€è¦§
            â”‚   â””â”€â”€ episode_{n}/
            â”‚       â”œâ”€â”€ layout.yaml     # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå®šç¾©
            â”‚       â””â”€â”€ metadata.json   # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            â”‚
            â”œâ”€â”€ renders/
            â”‚   â”œâ”€â”€ config.json         # æç”»è¨­å®š
            â”‚   â”œâ”€â”€ episode_{n}/
            â”‚   â”‚   â”œâ”€â”€ page_001.png    # æç”»æ¸ˆã¿ãƒšãƒ¼ã‚¸
            â”‚   â”‚   â”œâ”€â”€ page_002.png
            â”‚   â”‚   â””â”€â”€ ...
            â”‚   â””â”€â”€ thumbnails/
            â”‚       â””â”€â”€ episode_{n}/
            â”‚           â”œâ”€â”€ page_001_thumb.png
            â”‚           â””â”€â”€ ...
            â”‚
            â”œâ”€â”€ outputs/
            â”‚   â”œâ”€â”€ manga.pdf           # PDFå½¢å¼ï¼ˆãƒšãƒ¼ã‚¸é †JPEGçµ±åˆï¼‰
            â”‚   â”œâ”€â”€ manga_images.zip    # ZIPå½¢å¼ï¼ˆJPEGç”»åƒï¼‹YAMLè¨­å®šï¼‰
            â”‚   â””â”€â”€ metadata.json       # æˆæœç‰©ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            â”‚
            â””â”€â”€ state/
                â”œâ”€â”€ job_progress.json   # ã‚¸ãƒ§ãƒ–é€²æ—çŠ¶æ…‹
                â””â”€â”€ resume_data.json    # å†é–‹ç”¨ãƒ‡ãƒ¼ã‚¿
```

### Migration Strategy (Drizzle)

- **Drizzle Kit**: ã‚¹ã‚­ãƒ¼ãƒã‹ã‚‰è‡ªå‹•ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
- **ç’°å¢ƒåˆ¥ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: é–‹ç™ºç’°å¢ƒï¼ˆSQLiteï¼‰ã€æœ¬ç•ªç’°å¢ƒï¼ˆD1ï¼‰
- **å‹å®‰å…¨æ€§**: TypeScriptã«ã‚ˆã‚‹ã‚¹ã‚­ãƒ¼ãƒã¨ã‚¯ã‚¨ãƒªã®å‹ãƒã‚§ãƒƒã‚¯
- **ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†**: `drizzle/migrations/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ç®¡ç†
- **ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒãƒ³ãƒ‰**:
  ```bash
  # ã‚¹ã‚­ãƒ¼ãƒå¤‰æ›´ã‹ã‚‰ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
  npx drizzle-kit generate

  # é–‹ç™ºç’°å¢ƒé©ç”¨
  npx drizzle-kit migrate

  # æœ¬ç•ªç’°å¢ƒé©ç”¨ï¼ˆD1ï¼‰
  npx wrangler d1 migrations apply novel2manga
  ```
- **ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥**: Drizzleãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©å†…ã§è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†

## Storage and Database Abstraction

### ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æŠ½è±¡åŒ–è¨­è¨ˆï¼ˆ2025-08-01è¿½åŠ ï¼‰

```typescript
// Custom Storage Interfaceï¼ˆWeb Storage APIã¨ã®ç«¶åˆã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
interface NovelStorage {
  put(key: string, value: string | Buffer, metadata?: Record<string, string>): Promise<void>;
  get(key: string): Promise<{ text: string; metadata?: Record<string, string> } | null>;
  delete(key: string): Promise<void>;
  exists(key: string): Promise<boolean>;
}

// Drizzle Database Connection
interface DrizzleDatabase {
  select(): SelectQueryBuilder;
  insert(table: SQLiteTable): InsertQueryBuilder;
  update(table: SQLiteTable): UpdateQueryBuilder;
  delete(table: SQLiteTable): DeleteQueryBuilder;
  batch(queries: any[]): Promise<any[]>;
}

// Environment-specific Implementationsï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰
// src/lib/storage/ ã§å®Œå…¨å®Ÿè£…æ¸ˆã¿
/*
class LocalFileStorage implements NovelStorage {
  // ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ä¿å­˜å®Ÿè£…
}
class R2Storage implements NovelStorage {
  // Cloudflare R2ã¸ã®ä¿å­˜å®Ÿè£…
}
*/

// Drizzleçµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
class DatabaseService {
  private db: DrizzleDatabase

  constructor() {
    if (process.env.NODE_ENV === 'development') {
      // SQLite + Drizzle
      const sqliteDb = new Database(dbConfig.path)
      this.db = drizzle(sqliteDb, { schema })
    } else {
      // D1 + Drizzle
      this.db = drizzle(globalThis.DB, { schema })
    }
  }
}

// Storage Factoryï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰
// src/services/storage.ts ã§å®Œå…¨å®Ÿè£…æ¸ˆã¿
/*
export class StorageFactory {
  static async getNovelStorage(): Promise<NovelStorage>
  static async getChunkStorage(): Promise<NovelStorage>
  static async getAnalysisStorage(): Promise<NovelStorage>
  static async getLayoutStorage(): Promise<NovelStorage>
  static async getRenderStorage(): Promise<NovelStorage>
  static async getDatabase(): Promise<DatabaseService>
}
*/
```

## Error Handling

### ã‚¨ãƒ©ãƒ¼å‡¦ç†æˆ¦ç•¥ï¼ˆ2025-08-01æ›´æ–°ï¼‰

```typescript
// APIã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹
export class ApiError extends Error {
  constructor(
    message: string,
    public statusCode: number,
    public code?: string,
    public details?: any
  ) {
    super(message);
    this.name = 'ApiError';
  }
}

// ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ
export function createErrorResponse(
  error: unknown,
  defaultMessage: string = 'Internal server error'
): Response {
  if (error instanceof ApiError) {
    return NextResponse.json(
      {
        error: error.message,
        code: error.code,
        details: error.details
      },
      { status: error.statusCode }
    );
  }

  const message = error instanceof Error ? error.message : defaultMessage;
  return NextResponse.json(
    { error: message },
    { status: 500 }
  );
}
```

### ã‚¨ãƒ©ãƒ¼ã‚·ãƒŠãƒªã‚ª

- ãƒ†ã‚­ã‚¹ãƒˆè§£æå¤±æ•—: é©åˆ‡ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼é€šçŸ¥
- Canvas APIå‡¦ç†ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã¸ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã¸ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¨ãƒ©ãƒ¼: ãƒ­ãƒ¼ã‚«ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒªãƒˆãƒ©ã‚¤

## Configuration Management

### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ 

```typescript
// src/config/app.config.ts
export const appConfig = {
  // ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²è¨­å®š
  chunks: {
    defaultChunkSize: 5000,        // ã€ã“ã“ã‚’è¨­å®šã€‘
    defaultOverlapSize: 500,       // ã€ã“ã“ã‚’è¨­å®šã€‘
    minChunkSize: 1000,
    maxChunkSize: 10000,
  },

  // LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š
  llm: {
    defaultProvider: 'openrouter', // ã€ã“ã“ã‚’è¨­å®šã€‘
    providers: {
      openai: { model: 'o3' }, // OpenAI o3 (reasoningãƒ¢ãƒ‡ãƒ«ã€temperatureãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã—)
      gemini: { model: 'gemini-2.5-flash', temperature: 0.7 },
      groq: { model: 'compound-beta', maxTokens: 8192 },
      local: { model: 'gpt-oss:20b', baseUrl: 'http://localhost:11434' },
      openrouter: { model: 'openai/gpt-oss-120b', temperature: 0.7 },
    },
  },

  // å‡¦ç†è¨­å®š
  processing: {
    maxConcurrentChunks: 3,        // ã€ã“ã“ã‚’è¨­å®šã€‘
    retryAttempts: 3,
    retryDelay: 1000,
    cacheEnabled: true,
    cacheTTL: 86400000, // 24æ™‚é–“
  },

  // LLMãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³è¨­å®š
  llmFallbackChain: ['openrouter', 'gemini', 'claude'], // ã€ã“ã“ã‚’è¨­å®šã€‘
};
```

### è¨­å®šã®å„ªå…ˆé †ä½

1. **ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤** (app.config.ts)
2. **ç’°å¢ƒå¤‰æ•°ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰** (process.env)
3. **ãƒ©ãƒ³ã‚¿ã‚¤ãƒ è¨­å®š** (APIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)

### ç’°å¢ƒå¤‰æ•°

```bash
# .env - ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã®ã¿
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=...
GROQ_API_KEY=gsk_...
OPENROUTER_API_KEY=sk-or-...

# ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ç”¨ç’°å¢ƒå¤‰æ•°
APP_LLM_DEFAULT_PROVIDER=openrouter
APP_CHUNKS_DEFAULT_SIZE=7000
APP_PROCESSING_MAX_CONCURRENT=5
```

## Cloudflare Bindings

### å‹å®šç¾©

```typescript
// src/types/cloudflare.d.ts
declare global {
  // R2 Bucket
  const NOVEL_STORAGE: R2Bucket;

  // D1 Database
  const DB: D1Database;

  // KV Namespace
  const CACHE: KVNamespace;

  // Environment Variables
  interface CloudflareEnv {
    NOVEL_STORAGE: R2Bucket;
    DB: D1Database;
    CACHE: KVNamespace;
    OPENAI_API_KEY?: string;
    GEMINI_API_KEY?: string;
    GROQ_API_KEY?: string;
    OPENROUTER_API_KEY?: string;
  }
}

export interface R2Bucket {
  put(key: string, value: ReadableStream | ArrayBuffer | string, options?: R2PutOptions): Promise<R2Object | null>;
  get(key: string, options?: R2GetOptions): Promise<R2ObjectBody | null>;
  delete(key: string): Promise<void>;
  list(options?: R2ListOptions): Promise<R2Objects>;
}

export interface D1Database {
  prepare(query: string): D1PreparedStatement;
  batch<T>(statements: D1PreparedStatement[]): Promise<D1Result<T>[]>;
  exec<T>(query: string): Promise<D1ExecResult>;
}
```

### wrangler.tomlè¨­å®š

```toml
name = "novel2manga"
compatibility_date = "2024-01-01"

[vars]
NEXT_PUBLIC_APP_NAME = "Novel2Manga"

[[d1_databases]]
binding = "DB"
database_name = "novel2manga"
database_id = "your-database-id"

[[r2_buckets]]
binding = "NOVEL_STORAGE"
bucket_name = "novel2manga-storage"

[[kv_namespaces]]
binding = "CACHE"
id = "your-kv-namespace-id"
```

## Security Considerations

### Authentication & Authorization

```mermaid
sequenceDiagram
    participant User
    participant NextAuth
    participant API
    participant DB

    User->>NextAuth: ãƒ­ã‚°ã‚¤ãƒ³
    NextAuth->>DB: èªè¨¼æƒ…å ±ç¢ºèª
    DB-->>NextAuth: ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±
    NextAuth-->>User: JWTãƒˆãƒ¼ã‚¯ãƒ³
    User->>API: APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ + JWT
    API->>API: ãƒˆãƒ¼ã‚¯ãƒ³æ¤œè¨¼
    API->>DB: æ¨©é™ç¢ºèª
    API-->>User: ãƒ¬ã‚¹ãƒãƒ³ã‚¹
```

### Data Protection

- å…¥åŠ›æ¤œè¨¼: Zodã«ã‚ˆã‚‹ã‚¹ã‚­ãƒ¼ãƒãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
- XSSå¯¾ç­–: Reactè‡ªå‹•ã‚¨ã‚¹ã‚±ãƒ¼ãƒ— + CSPè¨­å®š
- SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–: Drizzle ORMä½¿ç”¨
- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: å½¢å¼ã¨ã‚µã‚¤ã‚ºã®å³æ ¼ãªæ¤œè¨¼
- API ãƒ¬ãƒ¼ãƒˆåˆ¶é™: Upstashã«ã‚ˆã‚‹ãƒ¬ãƒ¼ãƒˆåˆ¶é™

### Security Best Practices

- OWASP Top 10å¯¾ç­–å®Ÿè£…
- ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹æ©Ÿå¯†æƒ…å ±ç®¡ç†
- HTTPSå¼·åˆ¶ã¨ã‚»ã‚­ãƒ¥ã‚¢ã‚¯ãƒƒã‚­ãƒ¼
- CORSãƒãƒªã‚·ãƒ¼ã®é©åˆ‡ãªè¨­å®š
- å®šæœŸçš„ãªä¾å­˜é–¢ä¿‚ã®è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³

## Performance & Scalability

### Performance Targets

| Metric | Target | Measurement |
|--------|--------|-------------|
| åˆæœŸè¡¨ç¤ºæ™‚é–“ (FCP) | < 1.5ç§’ | Lighthouse |
| API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ (p95) | < 200ms | APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ |
| çµµã‚³ãƒ³ãƒ†ç”Ÿæˆæ™‚é–“ | < 5ç§’/ãƒšãƒ¼ã‚¸ | Canvas APIæ¸¬å®š |
| ãƒ†ã‚­ã‚¹ãƒˆè§£æ | < 5ç§’/10,000æ–‡å­— | å‡¦ç†æ™‚é–“æ¸¬å®š |
| åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•° | > 1,000 | è² è·ãƒ†ã‚¹ãƒˆ |

### Caching Strategy

- **ãƒ–ãƒ©ã‚¦ã‚¶ã‚­ãƒ£ãƒƒã‚·ãƒ¥**: Next.jsè‡ªå‹•æœ€é©åŒ–ã€é™çš„ã‚¢ã‚»ãƒƒãƒˆ
- **CDN**: CloudflareçµŒç”±ã§ã®ç”»åƒé…ä¿¡
- **ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥**: 2å±¤æ§‹é€ 
  - **L1 - MemoryCache**: ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€é«˜é€Ÿã‚¢ã‚¯ã‚»ã‚¹ã€TTLç®¡ç†
  - **L2 - Cloudflare KV**: æ°¸ç¶šåŒ–ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«åˆ†æ•£ã€å¤§å®¹é‡å¯¾å¿œ

  ```typescript
  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥å®Ÿè£…ä¾‹
  async function getCachedData<T>(key: string): Promise<T | null> {
    // L1: MemoryCacheãƒã‚§ãƒƒã‚¯
    const memCached = memoryCache.get<T>(key);
    if (memCached) return memCached;

    // L2: Cloudflare KVãƒã‚§ãƒƒã‚¯
    const kvCached = await CACHE.get(key, 'json');
    if (kvCached) {
      memoryCache.set(key, kvCached, 3600); // 1æ™‚é–“ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥
      return kvCached as T;
    }

    return null;
  }
  ```
- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥**: D1ã‚¯ã‚¨ãƒªçµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥
- **Edge ã‚­ãƒ£ãƒƒã‚·ãƒ¥**: Cloudflare Tiered Cacheã«ã‚ˆã‚‹å¤šéšå±¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥
- **ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥**:
  - ãƒãƒ£ãƒ³ã‚¯åˆ†æçµæœ: 24æ™‚é–“TTL
  - çµ±åˆåˆ†æçµæœ: 7æ—¥é–“TTL
  - LRU eviction policy for MemoryCache

### Scalability Approach

- Cloudflare Workersã«ã‚ˆã‚‹ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¨ãƒƒã‚¸ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
- Mastraãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ä¸¦åˆ—å‡¦ç†
- å¤§è¦æ¨¡ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã®ã‚­ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…ï¼ˆCloudflare Queuesï¼‰
- D1ã®è‡ªå‹•ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½
- Cloudflareã®è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¨DDoSä¿è­·

## å®Ÿè£…çŠ¶æ³æ›´æ–°ï¼ˆ2025-08-07ï¼‰

### ğŸ¯ ç¾åœ¨ã®å®Ÿè£…çŠ¶æ³ï¼ˆç¾å®Ÿçš„è©•ä¾¡ï¼‰

**å®Ÿéš›ã®å®Œæˆç‡: 15%**

```
âœ… å®Œæˆ: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰UIã€å°èª¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€è¨­å®šç®¡ç†
ğŸš¨ æœªå®Œæˆ: Jobå‡¦ç†ã€LLMçµ±åˆã€åˆ†æå‡¦ç†ã€é€²æ—æ›´æ–°
âŒ æœªç€æ‰‹: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ†æã€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç”Ÿæˆã€ç”»åƒãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã€ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
```

### ğŸ”´ ç™ºè¦‹ã•ã‚ŒãŸè‡´å‘½çš„å•é¡Œ

#### 1. Job Status Endpointå®Œå…¨åœæ­¢
**ç¾è±¡**: 
- UIä¸Šã¯ã€Œå‡¦ç†ä¸­ã€è¡¨ç¤ºã ãŒå®Ÿéš›ã¯ä½•ã‚‚å‡¦ç†ã•ã‚Œã¦ã„ãªã„
- `/api/jobs/[jobId]/status`ãŒç¶™ç¶šçš„ã«500ã‚¨ãƒ©ãƒ¼
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰Jobãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿å–ã‚Œãªã„

**åŸå› **: `DatabaseService.getJobWithProgress()`ãŒä¾‹å¤–ã‚’throw

#### 2. Mastraã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµ±åˆå¤±æ•—  
**ç¾è±¡**:
- ãƒãƒ£ãƒ³ã‚¯åˆ†æãŒé–‹å§‹ã•ã‚Œãªã„
- LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨ã®æ¥ç¶šãŒç¢ºç«‹ã•ã‚Œãªã„
- ç’°å¢ƒå¤‰æ•°ã¯ã‚ã‚‹ãŒMastraè¨­å®šãŒä¸é©åˆ‡

**åŸå› **: LLM Factory ã®è¨­å®šãƒŸã‚¹ã¾ãŸã¯Mastraã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–å¤±æ•—

#### 3. åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œå…¨åœæ­¢
**ç¾è±¡**:
- å°èª¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã€è¡¨é¢çš„ã«ã¯JobãŒä½œæˆã•ã‚Œã‚‹ãŒå‡¦ç†ãŒé€²ã¾ãªã„  
- ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ãƒ»åˆ†æãƒ»ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ§‹æˆç­‰ãŒä¸€åˆ‡å®Ÿè¡Œã•ã‚Œãªã„

### ğŸš¨ ç·Šæ€¥ä¿®æ­£ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ï¼ˆå„ªå…ˆé †ï¼‰

#### Task 1: Job Statusèª­ã¿å–ã‚Šä¿®æ­£ [CRITICAL]
```typescript
// å•é¡Œ: src/services/database.ts ã® getJobWithProgress ãŒå¤±æ•—
// ä¿®æ­£å¿…è¦: ä¾‹å¤–ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨nullãƒã‚§ãƒƒã‚¯
async getJobWithProgress(id: string) {
  try {
    const job = await this.db.select().from(jobs).where(eq(jobs.id, id)).limit(1)
    if (!job[0]) return null
    
    return {
      ...job[0],
      progress: null // ä¸€æ—¦nullå›ºå®šã§åŸºæœ¬å‹•ä½œã‚’ç¢ºä¿
    }
  } catch (error) {
    console.error('getJobWithProgress error:', error)
    return null // ã‚¨ãƒ©ãƒ¼æ™‚ã¯nullã‚’è¿”ã—ã¦ç¶™ç¶š
  }
}
```

#### Task 2: LLMçµ±åˆã®åŸºæœ¬å‹•ä½œç¢ºèª [CRITICAL]
```typescript
// å•é¡Œ: src/utils/llm-factory.ts ã§ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼æ¥ç¶šå¤±æ•—
// ä¿®æ­£å¿…è¦: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã¨åŸºæœ¬æ¥ç¶šãƒ†ã‚¹ãƒˆ
export async function validateLLMConnection() {
  const providers = ['openai', 'openrouter', 'gemini']
  
  for (const provider of providers) {
    const config = getLLMProviderConfig(provider)
    if (config.apiKey) {
      console.log(`Testing ${provider} connection...`)
      // åŸºæœ¬æ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè£…
      return provider
    }
  }
  throw new Error('No working LLM provider found')
}
```

#### Task 3: åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¿®æ­£ [CRITICAL]  
```typescript
// å•é¡Œ: src/app/api/analyze/route.ts ã§Mastraã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—å¤±æ•—
// ä¿®æ­£å¿…è¦: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨æ®µéšçš„å‡¦ç†
try {
  // ã¾ãšã¯ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‹ã‚‰é–‹å§‹
  const simpleAnalysis = {
    summary: chunkText.substring(0, 100) + "...",
    characters: [],
    dialogues: [],
    scenes: [],
    highlights: []
  }
  
  // Mastraå‘¼ã³å‡ºã—ã¯å¾Œå›ã—ã€ã¾ãšã¯å›ºå®šå€¤ã§å‹•ä½œç¢ºèª
  await analysisStorage.put(analysisPath, JSON.stringify(simpleAnalysis))
  
} catch (error) {
  console.error('Analysis failed:', error)
  await dbService.updateJobError(jobId, error.message, 'analyze')
  throw error
}
```

### ğŸ“… æ®µéšçš„ä¿®å¾©è¨ˆç”»

#### Week 1: åŸºç›¤ä¿®å¾©
- [ ] Job Status APIã‚’æœ€ä½é™å‹•ä½œã•ã›ã‚‹
- [ ] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿æ›¸ãã®åŸºæœ¬å‹•ä½œç¢ºèª  
- [ ] ç°¡å˜ãªãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã§åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç–é€šã•ã›ã‚‹

#### Week 2: LLMçµ±åˆ
- [ ] 1ã¤ã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨ã®æ¥ç¶šã‚’ç¢ºç«‹
- [ ] Mastraã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºæœ¬å‹•ä½œç¢ºèª
- [ ] å®Ÿéš›ã®ãƒ†ã‚­ã‚¹ãƒˆåˆ†æå‡¦ç†ã‚’å®Ÿè£…

#### Week 3: å‡¦ç†å®Œæˆ
- [ ] å…¨åˆ†æã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè£…
- [ ] ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ†æãƒ»ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç”Ÿæˆã®åŸºæœ¬å®Ÿè£…
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½

### ğŸ”§ å®Œäº†æ¸ˆã¿æ©Ÿèƒ½ï¼ˆé™å®šçš„ï¼‰

1. **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰UIåŸºç›¤**
   - Next.js 15.3 + Tailwind CSS v4 æ§‹æˆ
   - RSC/Clientå¢ƒç•Œã®é©åˆ‡ãªåˆ†é›¢
   - ã‚µãƒ³ãƒ—ãƒ«å°èª¬ã®å³æ™‚èª­è¾¼æ©Ÿèƒ½ï¼ˆpublic/docs/é…ä¿¡ï¼‰
   - 200ä¸‡æ–‡å­—å…¥åŠ›å¯¾å¿œ

2. **è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ **
   - app.config.tsã§ã®ä¸€å…ƒç®¡ç†
   - LLMãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³è¨­å®šï¼ˆopenrouter â†’ gemini â†’ claudeï¼‰
   - ç’°å¢ƒåˆ¥ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸åˆ‡ã‚Šæ›¿ãˆ

3. **APIéª¨æ ¼**
   - ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®åŸºæœ¬æ§‹é€ ã¯å®Ÿè£…æ¸ˆã¿
   - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®åŸºæœ¬æ çµ„ã¿
   - ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æŠ½è±¡åŒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼

### âš ï¸ æ¨å®šä¿®å¾©æ™‚é–“

**åŸºæœ¬å‹•ä½œã¾ã§**: æœ€ä½2-3é€±é–“  
**å®Œå…¨æ©Ÿèƒ½ã¾ã§**: 2-3ãƒ¶æœˆ  

ç¾åœ¨ã®çŠ¶æ…‹ã§ã¯ã€Œãƒ‡ãƒ¢ç”»é¢ã€ä»¥ä¸Šã®ä¾¡å€¤ã¯æä¾›ã§ããªã„çŠ¶æ³ã§ã™ã€‚

## Testing Strategy

### Test Coverage Requirements

- **å˜ä½“ãƒ†ã‚¹ãƒˆ**: â‰¥85% ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼ˆãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
- **çµ±åˆãƒ†ã‚¹ãƒˆ**: å…¨APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨Mastraçµ±åˆ
- **E2Eãƒ†ã‚¹ãƒˆ**: ä¸»è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ­ãƒ¼
- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ**: æƒ³å®šãƒ”ãƒ¼ã‚¯æ™‚ã®2å€è² è·

### Testing Approach

1. **å˜ä½“ãƒ†ã‚¹ãƒˆ (Vitest)**
   ```typescript
   describe('TextAnalyzer', () => {
     it('should extract 5 elements from novel text', async () => {
       const result = await analyzer.analyze(sampleText);
       expect(result.characters).toHaveLength(3);
       expect(result.scenes).toBeDefined();
     });
   });
   ```

2. **çµ±åˆãƒ†ã‚¹ãƒˆ**
   - Mastra ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¢ãƒƒã‚¯
   - APIå¥‘ç´„ãƒ†ã‚¹ãƒˆ
   - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆ

3. **E2Eãƒ†ã‚¹ãƒˆ (Playwright)**
   - ãƒ†ã‚­ã‚¹ãƒˆæŠ•ç¨¿ã‹ã‚‰çµµã‚³ãƒ³ãƒ†ç”Ÿæˆãƒ•ãƒ­ãƒ¼
   - ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç·¨é›†æ©Ÿèƒ½ã®å‹•ä½œç¢ºèª
   - ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

4. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ**
   - k6ã«ã‚ˆã‚‹è² è·ãƒ†ã‚¹ãƒˆ
   - Canvas APIå‡¦ç†ã®ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
   - ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡º

### CI/CD Pipeline

```mermaid
graph LR
    A[ã‚³ãƒ¼ãƒ‰ãƒ—ãƒƒã‚·ãƒ¥] --> B[Lint & Format]
    B --> C[å‹ãƒã‚§ãƒƒã‚¯]
    C --> D[å˜ä½“ãƒ†ã‚¹ãƒˆ]
    D --> E[çµ±åˆãƒ†ã‚¹ãƒˆ]
    E --> F[OpenNextãƒ“ãƒ«ãƒ‰]
    F --> G[E2Eãƒ†ã‚¹ãƒˆ]
    G --> H[Cloudflareãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼]
    H --> I[ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ]
    I --> J[Cloudflare Workersæœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤]
```